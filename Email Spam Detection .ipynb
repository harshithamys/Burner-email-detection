{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd40248",
   "metadata": {},
   "source": [
    "# IMPORTING THE REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a25882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraires for EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#Impoering libraries necessary for Model Building and Training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8a2414-1625-4b77-a5e3-1ef0ac76d146",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Now you can use plt for plotting\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Now you can use plt for plotting\n",
    "plt.plot([1, 2, 3, 4])\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Simple Plot')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3dd7f3-d9f8-4115-a160-3c2ff3e4d216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9c4cd-59dd-4108-bc39-1b73c73cd8c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8409ef-7747-4082-8b75-e714e893c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22ea50f-3a94-4368-8045-2cfa7b52a188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9d34e-8f46-45f9-8a8b-60e0d82123dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae320f-bed5-4184-818a-f70a0213c145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afed1514",
   "metadata": {},
   "source": [
    "# LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57ef3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam_ham_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92fc51c",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fcb092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed:0','label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'label_num':'spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb9a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7fb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d62172",
   "metadata": {},
   "source": [
    "# VISUALISING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea50ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['spam'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pie(df['spam'].value_counts(), labels=['ham','spam'],autopct=\"%0.2f\", shadow = True)\n",
    "\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.axis('equal')  \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabf28e",
   "metadata": {},
   "source": [
    "# DOWNSAMPLING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ec384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling to balance the datasheet \n",
    "ham_msg = df[df.spam == 0]\n",
    "spam_msg = df[df.spam == 1]\n",
    "ham_msg = ham_msg.sample(n = len(spam_msg), random_state=42)\n",
    "\n",
    "# Plotting the counts of down sampled dataset\n",
    "balanced_data = ham_msg.append(spam_msg).reset_index(drop = True)\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.countplot(balanced_data.spam)\n",
    "plt.title('Distribution of Ham and Spam email messages after downsampling')\n",
    "plt.xlabel('Message types')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd1f7fc",
   "metadata": {},
   "source": [
    "# HANDLING NULL VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d79732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd7601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888ea0a",
   "metadata": {},
   "source": [
    "# HANDLING DUPLICATE VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2cf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25711373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0551e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f9636",
   "metadata": {},
   "source": [
    "# REMOVING UNECESSARY WORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d2568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('Subject', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aedac30",
   "metadata": {},
   "source": [
    "# REMOVING PUNCTUATIONS FROM THE EMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d696df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations_list = string.punctuation\n",
    "def remove_punctuations(text):\n",
    "\ttemp = str.maketrans('', '', punctuations_list)\n",
    "\treturn text.translate(temp)\n",
    "\n",
    "df['text']= df['text'].apply(lambda x: remove_punctuations(x))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae056ab",
   "metadata": {},
   "source": [
    "# REMOVING STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "\tstop_words = stopwords.words('english')\n",
    "\n",
    "\timp_words = []\n",
    "\n",
    "\t# Storing the important words\n",
    "\tfor word in str(text).split():\n",
    "\t\tword = word.lower()\n",
    "\n",
    "\t\tif word not in stop_words:\n",
    "\t\t\timp_words.append(word)\n",
    "\n",
    "\toutput = \" \".join(imp_words)\n",
    "\n",
    "\treturn output\n",
    "\n",
    "\n",
    "df['text'] = df['text'].apply(lambda text: remove_stopwords(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57070910",
   "metadata": {},
   "source": [
    "# PLOTTING WORD CLOUD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee52a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_word_cloud(data, typ):\n",
    "\temail_corpus = \" \".join(data['text'])\n",
    "\n",
    "\tplt.figure(figsize=(10, 10))\n",
    "\twc = WordCloud(background_color='white',\n",
    "\t\t\t\tmax_words=100,\n",
    "\t\t\t\twidth=200,\n",
    "\t\t\t\theight=100,\n",
    "\t\t\t\tcollocations=False).generate(email_corpus)\n",
    "\n",
    "\tplt.title(f'WordCloud for {typ} emails.', fontsize=15)\n",
    "\tplt.axis('off')\n",
    "\tplt.imshow(wc)\n",
    "\tplt.show()\n",
    "\tprint()\n",
    "\n",
    "\n",
    "plot_word_cloud(df[df['spam'] == 0], typ='Non - Spam')\n",
    "plot_word_cloud(df[df['spam'] == 1], typ='Spam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65088112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all tweet texts into a single string\n",
    "all_text = ' '.join(df['text'].values)\n",
    "# Remove URLs, mentions, and hashtags from the text\n",
    "all_text = re.sub(r'http\\S+', '', all_text)\n",
    "all_text = re.sub(r'@\\S+', '', all_text)\n",
    "all_text = re.sub(r'#\\S+', '', all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4049c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into individual words\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467fc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [word for word in words if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce4b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each word\n",
    "word_counts = Counter(words)\n",
    "top_words = word_counts.most_common(100)\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ae879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart of the most common words\n",
    "top_words = word_counts.most_common(10) # Change the number to show more/less words\n",
    "x_values = [word[0] for word in top_words]\n",
    "y_values = [word[1] for word in top_words]\n",
    "plt.bar(x_values, y_values)\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Most Commonly Used Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46826b45",
   "metadata": {},
   "source": [
    "# CLASSIFICATION MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as pd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c00be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0637602",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c52214",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca1038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db681945",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e31e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef04ac",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extraction = TfidfVectorizer(min_df = 1, stop_words = 'english', lowercase =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ccd1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_features = feature_extraction.fit_transform(x_train)\n",
    "x_test_features = feature_extraction.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22973fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db0ae4b",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de997b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the logistics regression model\n",
    "model = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_features, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a159a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_train_features)\n",
    "accuracy = accuracy_score(y_train, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae272435",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on training data : ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d7645",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test_features)\n",
    "accuracy = accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8417fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on testing data : ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618ce18",
   "metadata": {},
   "source": [
    "# CONFUSIN MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dfbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b98878",
   "metadata": {},
   "source": [
    "# CALSSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ada657",
   "metadata": {},
   "source": [
    "# SPLITTING THE DATA IN THE TRAIN TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(balanced_data['text'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tbalanced_data['spam'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\ttest_size = 0.2,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69312b95",
   "metadata": {},
   "source": [
    "# CONVERTING TRAINING AND VALIDATION DATA INTO VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b649734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the tokenizer\n",
    "token=Tokenizer(num_words = max_words)\n",
    "token.fit_on_texts(train_X)\n",
    "\n",
    "#Generating token embeddings\n",
    "Training_seq = token.texts_to_sequences(train_X)\n",
    "Training_pad = pad_sequences(Training_seq,\n",
    "\t\t\t\t\t\t\tmaxlen = 50,\n",
    "\t\t\t\t\t\t\tpadding = 'post',\n",
    "\t\t\t\t\t\t\ttruncating = 'post')\n",
    "\n",
    "Testing_seq = token.texts_to_sequences(test_X)\n",
    "Testing_pad = pad_sequences(Testing_seq,\n",
    "\t\t\t\t\t\t\tmaxlen = 50,\n",
    "\t\t\t\t\t\t\tpadding = 'post',\n",
    "\t\t\t\t\t\t\ttruncating = 'post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91956297",
   "metadata": {},
   "source": [
    "# BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Model\n",
    "#max_words = 10000\n",
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Embedding(max_words, 32, input_length=50),\n",
    "tf.keras.layers.LSTM(4),\n",
    "tf.keras.layers.Dense(32, activation='relu'),\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22d5b5",
   "metadata": {},
   "source": [
    "# COMPILING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17abca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "\t\t\tmetrics = ['accuracy'],\n",
    "\t\t\toptimizer = 'adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37a9eb3",
   "metadata": {},
   "source": [
    "# DEFINING CALLBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "es = EarlyStopping(patience=3,\n",
    "\t\t\t\tmonitor = 'val_accuracy',\n",
    "\t\t\t\trestore_best_weights = True)\n",
    "\n",
    "lr = ReduceLROnPlateau(patience = 2,\n",
    "\t\t\t\t\tmonitor = 'val_loss',\n",
    "\t\t\t\t\tfactor = 0.5,\n",
    "\t\t\t\t\tverbose = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da6979",
   "metadata": {},
   "source": [
    "# FITTING THE DATA IN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba14be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(Training_pad, train_Y,\n",
    "                    validation_data = (Testing_pad, test_Y),\n",
    "                    epochs = 30,\n",
    "                    verbose = 1,\n",
    "                    batch_size = 32,\n",
    "                    callbacks = [lr, es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938613b1",
   "metadata": {},
   "source": [
    "# EVALUATING THE MODEL ON THE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Testing_pad, test_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2510bc",
   "metadata": {},
   "source": [
    "# PLOTTING THE MODEL ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3021fd",
   "metadata": {},
   "source": [
    "# BUILDING A PREDICTIVE SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b144df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mail = [\"WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d91a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mail_features = feature_extraction.transform(input_mail)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cdfeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_new =model.predict(input_mail_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83828a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d06082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction_new[0]==0:\n",
    "    print('ham mail')\n",
    "    \n",
    "else:\n",
    "    print('spam mail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c4310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
